---
title: " Oracle soils Burkina Faso t = 0 (#4) "
author: "Frédéric Mahé"
date: '`r format(Sys.time(), "%d %B %Y")`'

output:
  rmarkdown::html_document:
    theme: lumen
    toc: yes
    toc_float: TRUE
    keep_md: yes
    # code_folding: hide
---

```{r setup, include=FALSE}
rm(list = ls()) # remove all objects before starting
knitr::opts_chunk$set(echo = TRUE)
```

***

#### load required packages

```{r packages, message=FALSE}
library(here)
library(tidyverse)
library(vegan)
```


# SSU rRNA metabarcoding (16S V3-V4)

## decontamination and subsampling

### variables and functions

```{r}
input <- "Oracle_soils_16S_341F_785R_87_samples.OTU.filtered.cleaved.nosubstringOTUs.mumu.table2"
title <- "Oracle MetaB t0 SSU assignment with Silva v138.1 (87 samples)"
rarefied_table <- str_replace(input, "table2", "table3")
useful_metadata <- c("OTU", "total", "amplicon", "length", "abundance",
                   "spread", "identity", "taxonomy", "references")
useless_metadata <- c("sequence", "quality", "cloud", "chimera")
min_target_size <- 10000  # minimal number of reads
problematic_sample <- "T-1_S82"
seed <- 123
n_subsamplings <- 100
```

Fix an automatic column type detection issue for sample
`r problematic_sample`:

```{r}
load_raw_16S_occurrence_data <- function(filename){
    here::here("data", "MetaB_t0", filename) %>%
        read_tsv(na = "0",
                 show_col_types = FALSE,
                 col_type = list(`T-1_S82` = col_double()))
}

. %>%
    select(OTU, starts_with("T-"), starts_with("OR-")) %>%
    pivot_longer(cols = -OTU,
                 names_to = "samples",
                 values_to = "reads") %>%
    filter(! is.na(reads)) %>%
    summarise(sum(reads)) %>%
    pull() -> count_all_reads
```


### preliminary taxonomic filtering

Remove unassigned entries and entries assigned to organelles:

```{r}
load_raw_16S_occurrence_data(input) %>%
    filter(! str_detect(taxonomy, "No_hit|Mitochondria|Chloroplast")) -> starting_table
```

How many reads were removed?

```{r}
load_raw_16S_occurrence_data(input) %>%
    count_all_reads -> reads_before

starting_table %>%
    count_all_reads -> reads_after
```

`r prettyNum(reads_before - reads_after, scientific=FALSE, big.mark=",")`
reads were removed. That's a 
`r prettyNum(100 * (1 - (reads_after / reads_before)), scientific=FALSE)`
% reduction.


clean up:

```{r}
rm(problematic_sample, reads_before, reads_after,
   load_raw_16S_occurrence_data, count_all_reads,
   input)
```


### list OTUs present in control samples

```{r}
## Extract control samples
starting_table %>%
    select(all_of(useful_metadata),
           starts_with("T-"),
           starts_with("OR-T-extr")) %>%
    pivot_longer(cols = -all_of(useful_metadata),
                 names_to = "samples",
                 values_to = "reads") %>%
    filter(! is.na(reads)) %>%
    count(OTU, wt = reads, sort = TRUE) -> controls
```

There are a total of
 `r prettyNum(controls %>% summarise(sum = sum(n)) %>% pull(), scientific=FALSE, big.mark=",")`
 reads in controls samples. Here is a view of the most abundant:


```{r echo = FALSE, results = 'asis'}
controls %>%
    slice(1:10) %>%
    left_join(starting_table %>%
              select(OTU, taxonomy),
              by = "OTU") %>%
    as.data.frame() -> tmp

knitr::kable(tmp, caption = "Top ten OTUs in control samples")

rm(tmp)
```

The most abundant OTU in control samples is the Enterobacterales
 *[Serratiae](https://en.wikipedia.org/wiki/Serratia)*, which can
be found in water, soil, plants, and animals.


### decontamination

Compute the total number of reads for each OTU present in control
samples. That sum is then substracted from all occurrences of that OTU
in true samples. The rationale is as follows:

- if an OTU is abundant in control samples, but rare in true samples,
  then it is a contamination specific to the control samples, and it
  will be eliminated by the substraction (i.e, final abundance is 0),
- if an OTU is present in control samples, and present in true samples
  (systematic contamination, will be mitigated by the substraction),
 - if an OTU is rare in control samples, but abundant in true samples
  (cross-talk, will be eliminated/mitigated by the substraction)

Control samples can be eliminated from the statistical analysis after
the substraction (all OTUs present in control samples have been zeroed
out).


```{r}
starting_table %>%
    select(-all_of(useless_metadata)) %>%
    pivot_longer(cols = -all_of(useful_metadata),
                 names_to = "samples",
                 values_to = "reads") %>%
    filter(! is.na(reads)) %>%
    left_join(controls, by = "OTU") %>%
    mutate(reads = case_when(
               is.na(n)  ~ reads,
               n > reads ~ 0,
               TRUE      ~ reads - n)) %>%
    select(-n) %>%
    pivot_wider(names_from = samples,
                values_from = reads,
                values_fill = 0) -> d

rm(controls, starting_table)
```

Find sample sizes (number of reads per sample):

```{r}
d %>%
    select(-all_of(useful_metadata)) %>%
    pivot_longer(cols = everything(),
                 names_to = "samples",
                 values_to = "reads") %>%
    count(samples, wt = reads, name = "reads") %>%
    arrange(reads) -> sample_sizes
```

Find duplicated samples:

```{r}
sample_sizes %>%
    filter(str_detect(samples, "-S_")) %>%
    mutate(samples = str_remove(samples, "-S_.*")) %>%
    pull(samples) -> duplicated_samples

duplicated_samples
```

How many reads in these duplicated samples?

```{r}
sample_sizes %>%
    pivot_wider(names_from = samples,
                values_from = reads) %>%
    select(starts_with(duplicated_samples)) %>%
    pivot_longer(cols = everything(),
                 names_to = "samples",
                 values_to = "reads")
```

It seems that re-sequenced samples have more reads in all cases.

List small samples that will be eliminated:

```{r}
sample_sizes %>%
    filter(reads < min_target_size) %>%
    select(samples) %>%
    pull() -> small_samples

small_samples
```

Get the size of the smallest remaining samples:

```{r}
sample_sizes %>%
    filter(reads >= min_target_size) %>%
    summarize(min(reads)) %>%
    pull() -> smallest_sample_size
```

The smallest sample contains 
`r prettyNum(smallest_sample_size, scientific=FALSE, big.mark=",")` 
reads.

Isolate metadata columns, rename samples and prepare for rarefaction:

```{r}
d %>%
    select(all_of(useful_metadata)) -> metadata

. %>%
    pivot_longer(cols = -OTU,
                 names_to = "samples",
                 values_to = "reads") %>%
    mutate(samples = str_remove(samples, "-S_"),
           samples = str_replace(samples, "^OR-", "BU-"),
           samples = str_remove(samples, "_?S[:digit:]+$")) %>%
    pivot_wider(names_from = samples,
                values_from = reads) %>%
        select(-OTU) -> rename_samples

d %>%
    select(-all_of(c(useful_metadata, small_samples)), OTU) %>%
    rename_samples %>%
    t() -> occurrences_t
```


### rarefaction (random subsampling)

Randomly subsample the table, so all samples have the same number of
reads. Repeat the process `r n_subsamplings` times to make sure that
the final profile is as close as possible to the initial
distribution. Use a fix seed to make the process 100% repeatable. That
step can take several minutes to run.


```{r}
set.seed(seed)
matrix1 <- vegan::rrarefy(occurrences_t, smallest_sample_size)
for (i in 2:n_subsamplings) {
    matrix1 <- matrix1 + vegan::rrarefy(occurrences_t, smallest_sample_size)
}

matrix1 / n_subsamplings -> d_rarefied

rm(i, seed, n_subsamplings, d, matrix1)
```

Prepare to remove empty OTUs from the final rarefied table:

```{r}
. %>%
    pivot_longer(cols = starts_with("BU-"),
                 names_to = "samples",
                 values_to = "reads") %>%
    filter(reads > 0) %>%
    group_by(OTU) %>%
    mutate(total = sum(reads),
           spread = n()) %>%
    ungroup() %>%
    pivot_wider(names_from = samples,
                values_from = reads,
                values_fill = 0) %>%
    filter(total > 0) -> remove_empty_OTUs

. %>%
    mutate(total = NA,
           abundance = NA,
           spread = NA) -> remove_outdated_data
```


Rebuild and save the newly rarefied OTU table:

```{r}
bind_cols(metadata,
          d_rarefied %>%
          t() %>%
          as.data.frame() %>%
          as_tibble()) %>%
    remove_outdated_data %>%
    remove_empty_OTUs -> d

d %>%
    write_tsv(file = here::here("data", "MetaB_t0", rarefied_table))
```

How many reads per sample in the final table?

```{r}
d %>%
    pivot_longer(cols = starts_with("BU-"),
                 names_to = "samples",
                 values_to = "reads") %>%
    count(samples, wt = reads, name = "reads") %>%
    summary()

rm(d, d_rarefied)
```

As expected, there are now
 `r prettyNum(smallest_sample_size, scientific=FALSE, big.mark=",")`
 reads in all samples.



# shotgun metagenomics (SSU rRNA assignment with kraken)

## filtering and subsampling

In the first sequencing run (SAMA-12), a potential leak between 16
samples (see list below `dubious_samples`) lead us to order a new
sequencing (SAMA-21). This new sequencing was done twice (SAMA-21-1
and SAMA-21-2), with identical parameters. Note that the taxonomic
assignment was done on both R1 and R2 fastq files, yielding a R1 and
R2 file for each sample.

Let's assume it is safe to merge the results of SAMA-21-1 and
SAMA-21-2, and to discard the data from 16 dubious samples
(SAMA-12). For a given sample, the R1 and R2 assignments are also
merged.

However, it would be interesting to verify if the initial and
resequenced dubious samples are similar or not, or more similar to
their counterpart than to any other sample in the dataset. Similarly,
comparing the R1 and R2 assignments could be interesting. In other
words, is there a batch effect?

The best statistical approach for this comparison remains to be
discussed.


### variables and functions

```{r}
file_prefix <- "oracle_metaGt0_SAMA_"
file_suffix <- "_samples_kraken2_SSU_assignment_genuses.tsv"
run_names <- list("21_1", "21_2", "12")
min_target_size <- 10000  # minimal number of reads
seed <- 123
n_subsamplings <- 100
rarefied_table <- "oracle_metaGt0_79_samples_bracken_SSU_assignment_genuses_rarefied.table3"
```

```{r}
load_raw_rRNA_occurrence_data <- function(filename) {
    here::here("data", "MetaG_t0", filename) %>%
        read_tsv(show_col_types = FALSE, comment = "# ")
}


infer_name_contruct <- function(run_name) {
    if (run_name == "SAMA_12") {
        c("soil_code", "read_pass", "taxo_method")
    } else {
        c("soil_code", "tags", "lane", "read_pass", "taxo_method")
    }
}


parse_sample_names <- function(data, run_name) {
    data %>%
        colnames() %>%
        as_tibble_col(column_name = "sample") %>%
        filter(str_detect(sample, "^(OR|BU)-")) %>%
        separate(col = sample,
                 into = infer_name_contruct(run_name = run_name),
                 sep = "_",
                 remove = FALSE,
                 extra = "drop",
                 fill = "right") %>%
        select(sample, soil_code, read_pass, taxo_method) %>%
        mutate(run = run_name,
               soil_code = str_remove(soil_code, "OR-"),
               soil_code = str_replace(soil_code, "([:digit:]+)$", "-\\1"),
               soil_code = str_replace(soil_code, "--", "-"),
               soil_code = str_replace(soil_code, "-([:digit:])$", "-0\\1"),
               taxo_method = replace_na(taxo_method, "kraken"))
}


extract_sample_metadata <- function(filename) {
    run_name <- str_extract(filename, "SAMA_[:digit:]+(_[:digit:]+)?")
    
    load_raw_rRNA_occurrence_data(filename = filename) %>%
        parse_sample_names(data = ., run_name = run_name)
}


format_occurrence_data <- function(data) {
    data %>%
        pivot_longer(cols = matches("^(BU|OR)-"),
                     names_to = "sample",
                     values_to = "reads"
                     )
}


load_and_format_occurrence_data <- function(filename) {
    
    load_raw_rRNA_occurrence_data(filename = filename) %>%
        format_occurrence_data(data = .)
}

. %>%
    left_join(sequencing_metadata, by = "sample") %>%
    filter(! (sample %in% dubious_samples) &
           str_detect(taxonomy, "^k__(Archaea|Bacteria)") &
           ! str_detect(taxonomy, "No_hit|Mitochondria|Chloroplast") &
           taxo_method == "bracken" &
           reads > 0.0) %>%
    unite(soil_code, read_pass, col = "samples") %>%
    count(samples, taxonomy,
          wt = reads, name = "reads") %>%
    pivot_wider(names_from = samples,
                values_from = reads,
                values_fill = 0) -> filter_and_pool_resequenced_samples
```

Alternative code for `parse_sample_names()`: `soil_code =
str_replace(soil_code, "(?<![-[:digit:]])([[:digit:]]+)$",
"-\\1")`. In the SAMA21 resequencing, soil codes are in the form
`BU-SER11`, where `BU-SER-11` is expected. To fix that, we could use a
regular expression replacement. The regex looks for and captures a
group of one or more digit at the end of the string `[[:digit:]]+$`,
inserts a '-', and writes the group back. This is fine for SAMA21, but
nor for SAMA12 where soil codes are already in the form
`BU-SER-11`. Using the same regex would insert a second '-', like so
`BU-SER--11`. To avoid that we can use a more complex regex that will
insert a '-' only if the group of digits is not preceded by a '-' or a
digit `(?<![-[:digit:]])`.

That may seem too complex, an alternative is to mutate a second time
to remove extra '-', if any.


### preliminary filtering

Extract additional data from sample names (name of the run, R1 or R2,
assignment method):

```{r}
purrr::imap(run_names, ~ paste0(file_prefix, .x, file_suffix)) %>%
    purrr::map_dfr(extract_sample_metadata) -> sequencing_metadata
```

Make a list of re-sequenced samples:

```{r}
sequencing_metadata %>%
    filter(run != "SAMA_12") %>%
    distinct(soil_code) %>%
    pull() -> resequenced_samples
```


#### sequencing hodgepodge

- run `SAMA_12`: 80 samples, 1 failure, 16 samples with a risk of leakage,
- run `SAMA_21_1`: 16 samples
- run `SAMA_21_2`: 16 samples (same as `SAMA_21_1`)

Sequencing was done thrice (runs `SAMA_12`, `SAMA_21_1`, `SAMA_21_2`)
for 16 samples. There are different ways or strategies to deal with
that:

- 1) complete pool (`SAMA_12` + `SAMA_21_1` + `SAMA_21_2`),
- 2) partial pool (partial `SAMA_12` + (`SAMA_21_1` + `SAMA_21_2`)),
- 3) no pool (only `SAMA_12`),

It is also possible to discard `SAMA_12` entirely, but that would
result in a dataset of only 16 samples (instead of 79):

- no pool (only `SAMA_21_1` + `SAMA_21_2`)


#### strategy 1: complete pool

Make a list of dubious samples (i.e., samples that will be excluded,
None in that case):

```{r}
sequencing_metadata %>%
    filter(run == "") %>%
    pull(sample) -> dubious_samples
```


#### strategy 2: partial pool

Make a list of dubious samples (i.e., samples that will be excluded,
i.e. dubious `SAMA_12` samples):

```{r}
sequencing_metadata %>%
    filter(run == "SAMA_12" & soil_code %in% resequenced_samples) %>%
    pull(sample) -> dubious_samples
```


#### strategy 3: no pool

Use only `SAMA_12`, including dubious samples:

```{r}
sequencing_metadata %>%
    filter(run != "SAMA_12") %>%
    pull(sample) -> dubious_samples
```

(strong structuration due to differences between the R1 and R2 reads)


#### filter and pool

Pool all sequencing results, filter out dubious samples and phantom
OTUs, keep only the bracken results (recomputed number of reads) and
reads assigned to Archaea and Bacteria:

```{r}
purrr::imap(run_names, ~ paste0(file_prefix, .x, file_suffix)) %>%
    purrr::map_dfr(load_and_format_occurrence_data) %>%
    filter_and_pool_resequenced_samples -> big_table
```

warning: each sample is either raw or recomputed by bracken. We choose
to use the bracken values.


#### Inspect the distribution

```{r}
big_table %>%
    pivot_longer(cols = matches("^(BU|OR)-"),
                 names_to = "samples",
                 values_to = "reads") %>%
    count(samples, wt = reads, name = "reads") %>%
    arrange(reads) -> sample_sizes

sample_sizes %>%
    pull(samples) %>%
    length()
sample_sizes %>%
    head()
sample_sizes %>%
    tail()

sample_sizes %>%
    head(n = 1) %>%
    pull(reads) -> smallest_sample_size
```

As expected, there are now 158 samples (80 samples minus one, times
two for each read pass R1 and R2). The difference between the largest
and the smallest samples is larger than expected. That should be
investigated.

Note: in the function `filter_and_pool_resequenced_samples()`,
`taxonomy` and `#OTU ID` are equivalent (each ID corresponds to a
taxonomy, and each taxonomy corresponds to an ID). A bijection in
mathematical terms. There are no reads assigned to Mitochondria or
Chloroplast.


Clean up:

```{r}
rm(sample_sizes, file_prefix, file_suffix)
```


### rarefaction (random subsampling)

Randomly subsample the table, so all samples have the same number of
reads. Repeat the process `r n_subsamplings` times to make sure that
the final profile is as close as possible to the initial
distribution. Use a fix seed to make the process 100% repeatable. That
step can take several minutes to run.


Prepare a table for vegan:

```{r}
big_table %>%
    select(-taxonomy) %>%
    t() -> occurrences_t
```


Rarefy and compute average abundances:

```{r}
set.seed(seed)
matrix1 <- vegan::rrarefy(occurrences_t, smallest_sample_size)
for (i in 2:n_subsamplings) {
    matrix1 <- matrix1 + vegan::rrarefy(occurrences_t, smallest_sample_size)
}

matrix1 / n_subsamplings -> d_rarefied

rm(i, seed, n_subsamplings, matrix1, occurrences_t)
```


Rebuild and save the newly rarefied OTU table:

```{r}
. %>%
    t() %>%
    as.data.frame() %>%
    as_tibble() -> transform_back

. %>%
    bind_cols(big_table %>%
              select(taxonomy)) %>%
    relocate(taxonomy,
             .before = everything()) -> add_taxonomic_assignments

. %>%
    pivot_longer(cols = matches("^(BU|OR)-"),
                 names_to = "samples",
                 values_to = "reads") %>%
    filter(reads > 0) %>%
    pivot_wider(names_from = samples,
                values_from = reads,
                values_fill = 0) -> remove_empty_OTUs

d_rarefied %>%
    transform_back %>%
    add_taxonomic_assignments %>%
    remove_empty_OTUs -> big_table_rarefied

big_table_rarefied %>%
    write_tsv(file = here::here("data", "MetaG_t0", rarefied_table))

rm(big_table, d_rarefied)
```


How many reads per sample in the final table?

```{r}
big_table_rarefied %>%
    pivot_longer(cols = matches("^(BU|OR)-"),
                 names_to = "samples",
                 values_to = "reads") %>%
    count(samples, wt = reads, name = "reads") %>%
    summary()
```

As expected, there are now
 `r prettyNum(smallest_sample_size, scientific=FALSE, big.mark=",")`
 reads in all samples.


***

```{r}
sessionInfo()
rm(list = ls())
```
